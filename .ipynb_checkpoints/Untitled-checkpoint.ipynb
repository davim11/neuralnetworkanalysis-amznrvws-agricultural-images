{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403b11d-d7c7-4cb6-82e9-eafa325485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D604: Task 1 Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f7d629-3692-4186-baee-010ce8750735",
   "metadata": {},
   "source": [
    "A1.\n",
    "Can a neural network model accurately classify RGB images of plant seedlings into their respective species to support automated weed detection and crop management in agricultural settings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f8e85d-50b2-48fa-9fa7-58e795ae73d5",
   "metadata": {},
   "source": [
    "A2. \n",
    "One goal of the analysis is to build a neural network model that will classify the twelve seedling species with an accuracy of at least 85%. Since the dataset includes 4,750 images across twelve classes, the dataset’s size will support training for multi-class classification. Another goal of the analysis is to identify any visual features that set crop seedlings apart from weeds to provide insights for decision-making. This is achievable since the RBG images contain detailed visual data that can be analyzed after training. A third goal is to minimize the misclassification of crops as weeds and prevent the unnecessary removal of valuable plants by correctly identifying them. Precision and recall can be balanced by identifying these false positives, and the labeled data in labels.csv supports this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33baaa81-aed0-4efa-9471-5c4557209a0f",
   "metadata": {},
   "source": [
    "A3.\n",
    "I will use a Convolutional Neural Network (CNN) for this analysis. CNNs are a good choice for multi-class image classification. They are equipped to process the 4750 RGB images and classify them into twelve categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1da911-6f25-4933-96dc-1071918ec780",
   "metadata": {},
   "source": [
    "A4.\n",
    "CNNs use convolutional layers to find spatial patterns such as leaf edges, vein structures, and color variations. CNNs can also use color information to distinguish species of plants, which will be helpful when differentiating a weed from a plant. They are widely used in agriculture already for weed detection and crop monitoring. CNN also uses pooling layers to reduce the image dimensionality. This makes the training process easier to process with a large dataset. Finally, CNN works well with a SoftMax output layer to handle the twelve-class classification process well. Other alternative methods may struggle with high-dimensional image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bb541-7ecb-412a-a215-04834302c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load labels\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "# Print column names and first few rows to inspect\n",
    "print(\"Column names:\", labels.columns.tolist())\n",
    "print(\"First 5 rows:\\n\", labels.head())\n",
    "\n",
    "class_counts = labels.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e523d-92ff-4884-ac91-106680e76cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1a: Visualization for class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Seedling Species')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png')  # Save for screenshot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca8a61-5b13-4ffc-9477-279c485387df",
   "metadata": {},
   "source": [
    "B1a.\n",
    "The bar chart in Figure 1 was created to show the distribution of the twelve seedling species in the dataset. The plot uses the counts of each unique value in the labels.csv sheet.\n",
    "\n",
    "Figure 1: Distribution of Seedling Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a7957-fcea-4a98-a3f7-6e00514f3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1b: Sample images with associated labels\n",
    "images = np.load(\"images.npy\")  # Shape: (4750, 128, 128, 3)\n",
    "\n",
    "# Get unique classes and one sample per class\n",
    "unique_classes = labels.iloc[:, 0].unique()\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, species in enumerate(unique_classes):\n",
    "    idx = labels[labels.iloc[:, 0] == species].index[0]  # First occurrence\n",
    "    plt.subplot(2, 6, i + 1)  # 2 rows, 6 cols for 12 classes\n",
    "    plt.imshow(images[idx])\n",
    "    plt.title(species, fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png')  # Save for screenshot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990a3fc-1798-4b30-b252-bbea1cdfff42",
   "metadata": {},
   "source": [
    "B1b.\n",
    "The grid in Figure 2 displays sample images showing one image per species with its corresponding label. \n",
    "Figure 2: 2x6 Grid of 12 Seedling Species Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cea019-8c91-421a-b36c-f891527d5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2: Perform Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff52c9-1e1d-43fa-a2aa-c0d6864ee740",
   "metadata": {},
   "source": [
    "B2.\n",
    "The steps taken to augment the images include a ±30° horizontal flip, brightness adjustment by ±20%, and zoom by ±20%. These steps enhance the diversity of the data and mimic real-world variations in photography. This helps prevent any overfitting with the approximately 395 images per class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841ed46-839b-4e4a-bbb6-e981643a55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3: Normalize the Images\n",
    "images_normalized = images.astype('float32') / 255.0\n",
    "print(images_normalized.min(), images_normalized.max())  # Should print 0.0, 1.0\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images_normalized, labels.iloc[:, 0], test_size=0.3, stratify=labels.iloc[:, 0], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052fb012-cb55-4a91-b5e5-4abd1a5af7b9",
   "metadata": {},
   "source": [
    "B3. \n",
    "In this section, the pixel values are scaled to [0, 1] to standardize input for the CNN. This aids in the optimization process and improves compatibility with common frameworks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266f388-bdc8-48d9-bb1d-1a32ad297d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4: Perform Training (70%), Validation (15%), and  Test (15%) Split\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "print(X_train.shape, X_val.shape, X_test.shape)  # (3325, 128, 128, 3), (712, 128, 128, 3), (713, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4dfa2-1ac5-42bf-9a29-95e81caa705c",
   "metadata": {},
   "source": [
    "B4. \n",
    "By keeping 70% of the data in the training dataset and putting 15% in the validation and test sets, respectively, it can be ensured that sufficient data is used for training and evaluation. This preserves the overall class balance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84353706-2529-4d6c-aa98-34105e5b0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B5: Encode the target feature for all datasets\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)  # y_train from split\n",
    "y_val_encoded = le.transform(y_val)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "y_train_onehot = to_categorical(y_train_encoded, num_classes=12)\n",
    "y_val_onehot = to_categorical(y_val_encoded, num_classes=12)\n",
    "y_test_onehot = to_categorical(y_test_encoded, num_classes=12)\n",
    "print(y_train_onehot.shape)  # (3325, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb717b-1168-462c-ab35-186ef8ac6a84",
   "metadata": {},
   "source": [
    "B5. \n",
    "The labels are encoded as integers (0-11) and then one-hot encoded into 12D vectors for multi-class classification, matching the CNNs SoftMax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975afde-bb80-4c83-9f1c-ccd9ab2e4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6: Provide a copy of all datasets\n",
    "np.save('task1_X_train.npy', X_train)\n",
    "np.save('task1_X_val.npy', X_val)\n",
    "np.save('task1_X_test.npy', X_test)\n",
    "np.save('task1_y_train_onehot.npy', y_train_onehot)\n",
    "np.save('task1_y_val_onehot.npy', y_val_onehot)\n",
    "np.save('task1_y_test_onehot.npy', y_test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c831f-c63f-4c3b-bc71-206f28532e3e",
   "metadata": {},
   "source": [
    "B6. \n",
    "A copy of all datasets have been uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82635d38-991d-44bc-aba4-b700fb7e3af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
