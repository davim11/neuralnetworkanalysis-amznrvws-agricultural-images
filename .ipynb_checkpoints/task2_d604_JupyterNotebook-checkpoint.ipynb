{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111e38e-3776-4c21-ad7d-a13e6036eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D604: Advanced Analytics\n",
    "# Task2: Sentiment Analysis Using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601ee93-cc38-4d06-a35a-d07ba9e12196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Load Dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('task2data_amazon_cells_labelled.txt', sep='\\t', header=None, names=['review', 'label'])\n",
    "print(data.head())\n",
    "print(f\"Total reviews: {len(data)}\")\n",
    "print(f\"Label distribution:\\n{data['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0667a-507c-4139-b057-49e6fe876df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1: Exploratory Data Analysis\n",
    "def has_unusual_chars(text):\n",
    "    unusual = re.findall(r'[^\\w\\s.,!?]', text)\n",
    "    return unusual if unusual else None\n",
    "\n",
    "data['unusual_chars'] = data['review'].apply(has_unusual_chars)\n",
    "unusual_reviews = data[data['unusual_chars'].notnull()]\n",
    "print(f\"Reviews with unusual characters: {len(unusual_reviews)}\")\n",
    "print(unusual_reviews[['review', 'unusual_chars']].head())\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(data['review'])\n",
    "sequence_lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "mean_len = np.mean(sequence_lengths)\n",
    "percentile_95 = np.percentile(sequence_lengths, 95)\n",
    "max_len = int(percentile_95)\n",
    "print(f\"Mean sequence length: {mean_len:.2f}\")\n",
    "print(f\"95th percentile: {percentile_95}\")\n",
    "print(f\"Chosen max length: {max_len}\")\n",
    "\n",
    "plt.hist(sequence_lengths, bins=30)\n",
    "plt.title(\"Distribution of Sequence Lengths\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14c92a-05f9-4da7-ba09-565dd6479d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2: Tokenization Process\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "data['review_normalized'] = data['review'].apply(normalize_text)\n",
    "tokenizer = Tokenizer(num_words=2000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['review_normalized'])\n",
    "sequences = tokenizer.texts_to_sequences(data['review_normalized'])\n",
    "\n",
    "print(\"Word Index (sample):\", list(tokenizer.word_index.items())[:5])\n",
    "print(\"Sample sequence:\", sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f43bd1-4c2e-4224-9269-345407f629fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3: Padding Process\n",
    "padded_sequences = pad_sequences(sequences, maxlen=23, padding='pre', truncating='pre')\n",
    "print(\"Sample padded sequence (review 0):\", padded_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410703a6-23a2-457d-a806-d41ce8a870cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4: Number of Sentiment Categories and Activation Function\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=1879, output_dim=128),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e72017-37be-48f6-9dd5-7637c8fa2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B5: Data Preparation Steps - Split into Training, Validation, and Test Sets\n",
    "X = padded_sequences\n",
    "y = data['label'].values\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} reviews\")\n",
    "print(f\"Validation set: {len(X_val)} reviews\")\n",
    "print(f\"Test set: {len(X_test)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489621a-a283-4511-a8f1-aa06580dbb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6: Provide a Copy of the Prepared Dataset - Export to Text File\n",
    "with open('task2_prepared_dataset.txt', 'w') as f:\n",
    "    f.write(\"Training Set (700 reviews):\\n\")\n",
    "    for i in range(len(X_train)):\n",
    "        f.write(f\"X_train[{i}]: {X_train[i].tolist()} | y_train[{i}]: {y_train[i]}\\n\")\n",
    "    \n",
    "    f.write(\"\\nValidation Set (150 reviews):\\n\")\n",
    "    for i in range(len(X_val)):\n",
    "        f.write(f\"X_val[{i}]: {X_val[i].tolist()} | y_val[{i}]: {y_val[i]}\\n\")\n",
    "    \n",
    "    f.write(\"\\nTest Set (150 reviews):\\n\")\n",
    "    for i in range(len(X_test)):\n",
    "        f.write(f\"X_test[{i}]: {X_test[i].tolist()} | y_test[{i}]: {y_test[i]}\\n\")\n",
    "\n",
    "print(\"Prepared dataset saved to 'task2_prepared_dataset.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8d690-a03d-4a08-9087-4cebfca65279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1: Provide the Output of the Model Summary\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=1879, output_dim=128),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.build(input_shape=(None, 23))  # Build with input shape (batch_size, max_len)\n",
    "print(\"\\nC1: Model Summary\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd38c7-462a-49f9-bb1b-ebc81dc040e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C3: Define Hyperparameters\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Note: Training will occur in Part D, not here\n",
    "print(\"\\nC3: Hyperparameters Defined\")\n",
    "print(\"Loss: binary_crossentropy\")\n",
    "print(\"Optimizer: adam\")\n",
    "print(\"Stopping Criteria: EarlyStopping with patience=5 on val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34c089-48da-4c86-b313-789014b9c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1: Train the Model with Stopping Criteria\n",
    "print(\"\\nD1: Training the Model\")\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50,  # Max epochs, expecting early stopping to cut it short\n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    callbacks=[early_stopping], \n",
    "                    verbose=1)\n",
    "\n",
    "# Get the number of epochs trained\n",
    "num_epochs = len(history.history['loss'])\n",
    "print(f\"Training stopped after {num_epochs} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe2136-bde1-40a3-a9f0-8d263b3a0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E: Save the trained Model\n",
    "model.save('task2_sentiment_model.keras')\n",
    "print(\"Trained model saved as 'task2_sentiment_model.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8ea5c-4286-46be-b9b5-2d940325408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D2: Assess Model Fitness Using Accuracy and Loss Metrics\n",
    "print(\"\\nD2: Model Fitness Assessment\")\n",
    "# Final training and validation metrics from history (last epoch)\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {final_val_acc:.4f}\")\n",
    "\n",
    "# Test set evaluation\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f971f6-e409-4821-9c47-3b088986a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D3: Visualize Training Process with Loss and Accuracy Metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nD3: Visualizations of Training Process\")\n",
    "# Plot Training & Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
